<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <title>Video Capture Example</title>
    <link href="assets/css/js_example_style.css" rel="stylesheet" type="text/css" />
</head>

<body>
    <h2>Video Capture Example</h2>
    <p>
        Click <b>Start/Stop</b> button to start or stop the camera capture.<br>
    </p>
    <div>
        <div class="control"><button id="startAndStop" disabled>Start</button></div>
        <div class="control">
            <button id="addUser" disabled>Add User</button>
            <input id="username" type="text" />
        </div>
        <div class="control"><button id="train" disabled>Train</button></div>
    </div>
    <p class="err" id="errorMessage"></p>
    <div>
        <table cellpadding="0" cellspacing="0" width="0" border="0">
            <tr>
                <td>
                    <video id="videoInput" width=320 height=240></video>
                </td>
                <td>
                    <canvas id="canvasOutput" width=320 height=240></canvas>
                </td>
                <td>
                    <span id="captureCount">0/100</span>
                    <canvas id="imageOutput" width=120 height=120></canvas>
                </td>
                <td></td>
            </tr>
            <tr>
                <td>
                    <div class="caption">videoInput</div>
                </td>
                <td>
                    <div class="caption">canvasOutput</div>
                </td>
                <td></td>
                <td></td>
            </tr>
        </table>
    </div>
    <script src="https://webrtc.github.io/adapter/adapter-5.0.4.js" type="text/javascript"></script>
    <script src="assets/js/utils.js" type="text/javascript"></script>

    <script type="text/javascript">
        let utils = new Utils('errorMessage');

        let streaming = false;
        let videoInput = document.getElementById('videoInput');
        let startAndStop = document.getElementById('startAndStop');

        let addUser = document.getElementById('addUser');
        let username = document.getElementById('username');

        let trainBtn = document.getElementById('train');
        let captureCount = document.getElementById('captureCount');
        let canvasOutput = document.getElementById('canvasOutput');
        let canvasContext = canvasOutput.getContext('2d');
        let frames = [];
        let ids = [];

        startAndStop.addEventListener('click', () => {
            if (!streaming) {
                utils.clearError();
                utils.startCamera('qvga', onVideoStarted, 'videoInput');
            } else {
                utils.stopCamera();
                onVideoStopped();
            }
        });

        trainBtn.addEventListener('click', () => {
            if (frames.length > 5) {
                onTrainNewUser()
            }
        });

        function onTrainNewUser() {
            clf = cv.face.LBPHFaceRecognizer_create()
            clf.train(frames, ids)
            clf.write("assets/data/classifiers/" + username.value + "_classifier.xml")
        }
        function onVideoStarted() {
            streaming = true;
            startAndStop.innerText = 'Stop';
            videoInput.width = videoInput.videoWidth;
            videoInput.height = videoInput.videoHeight;
            let video = document.getElementById('videoInput');
            let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
            let dst = new cv.Mat(video.height, video.width, cv.CV_8UC1);
            let gray = new cv.Mat();
            let cap = new cv.VideoCapture(video);
            let faces = new cv.RectVector();
            let classifier = new cv.CascadeClassifier();
            let utils = new Utils('errorMessage');
            let faceCascadeFile = 'haarcascade_frontalface_default.xml'; // path to xml
            utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
                classifier.load(faceCascadeFile); // in the callback, load the cascade from file 
            });

            let id = 1;
            frames = [];
            ids = [];
            let frame = new cv.Mat(100, 100, cv.CV_8UC1);
            const FPS = 24;
            function processVideo() {
                try {
                    if (!streaming) {
                        // clean and stop.
                        src.delete();
                        dst.delete();
                        frame.delete();
                        return;
                    }
                    let begin = Date.now();
                    // start processing.
                    cap.read(src);
                    src.copyTo(dst);
                    cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
                    try {
                        classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
                        console.log(faces.size());
                    } catch (err) {
                        console.log(err);
                    }
                    for (let i = 0; i < faces.size(); ++i) {
                        let face = faces.get(i);
                        let point1 = new cv.Point(face.x, face.y);
                        let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                        let rect = new cv.Rect(face.x, face.y, face.width, face.height);
                        cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
                        frame = gray.roi(rect);

                    }
                    cv.imshow('canvasOutput', dst);
                    if (frame && id <= 100) {
                        frames.push(frame);
                        ids.push(id);
                        captureCount.innerText = `${id}/100`;
                        id += 1;
                        cv.imshow('imageOutput', frame);
                    }

                    // schedule the next one.
                    let delay = 1000 / FPS - (Date.now() - begin);
                    setTimeout(processVideo, delay);
                } catch (err) {
                    utils.printError(err);
                }
            };

            // schedule the first one.
            setTimeout(processVideo, 0);
        }

        function onVideoStopped() {
            streaming = false;
            canvasContext.clearRect(0, 0, canvasOutput.width, canvasOutput.height);
            startAndStop.innerText = 'Start';
        }

        utils.loadOpenCv(() => {
            startAndStop.removeAttribute('disabled');
            addUser.removeAttribute('disabled');

        });
        username.addEventListener('change', (e) => {
            if (e.target.value != '') {
                trainBtn.removeAttribute('disabled');
            }
        })
    </script>
</body>

</html>